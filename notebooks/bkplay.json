{"paragraphs":[{"text":"%spark\n\n// These imports not needed for Spark-SQL, but I do need them in order to do rdd-level C* table work\nimport com.datastax.spark.connector._\nimport com.datastax.spark.connector.cql.CassandraConnector\n\n// These imports not needed, but including them because example code uses them\n// (WriteRead.scala in SparkBuildExamples in my Intellij)\n//import org.apache.spark.sql.{SaveMode, SparkSession}\n//import org.apache.spark.sql.cassandra._","user":"anonymous","dateUpdated":"2019-06-15T18:32:21+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1560622499659_-1800462454","id":"20190615-181459_1816041684","dateCreated":"2019-06-15T18:14:59+0000","dateStarted":"2019-06-15T18:32:21+0000","dateFinished":"2019-06-15T18:32:22+0000","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:1539"},{"text":"%spark\n\n// create a literal RDD just to prove that spark access is working\n\nval list = List( (\"Frozen\", 2013), (\"Toy Story\", 1995), (\"WALL-E\", 2008) )\nval rdd = sc.parallelize(list)\nrdd.take(3)\n","user":"anonymous","dateUpdated":"2019-06-15T18:29:28+0000","config":{"colWidth":12,"editorMode":"ace/mode/scala","results":{},"enabled":true,"editorSetting":{"language":"scala","editOnDblClick":false}},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1560614209693_-483172676","id":"20190529-160118_1285216078","dateCreated":"2019-06-15T15:56:49+0000","dateStarted":"2019-06-15T18:29:28+0000","dateFinished":"2019-06-15T18:29:30+0000","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:1540"},{"text":"%cassandra\n\n// prove that cql access is working\n\ndescribe keyspace analytics_workshop;","user":"anonymous","dateUpdated":"2019-06-15T18:29:41+0000","config":{"colWidth":12,"editorMode":"ace/mode/undefined","results":{},"enabled":true,"editorSetting":{"language":"scala","editOnDblClick":false}},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1560614209703_-497793134","id":"20190529-161317_30181527","dateCreated":"2019-06-15T15:56:49+0000","dateStarted":"2019-06-15T18:29:41+0000","dateFinished":"2019-06-15T18:29:52+0000","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:1541"},{"text":"%cassandra\n\n// prove that you can read the countries table with cql\n\nselect * from analytics_workshop.countries;","user":"anonymous","dateUpdated":"2019-06-15T18:29:59+0000","config":{"colWidth":12,"editorMode":"ace/mode/undefined","results":{},"enabled":true,"editorSetting":{"language":"scala","editOnDblClick":false}},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1560614209704_-499716879","id":"20190530-142647_1892250973","dateCreated":"2019-06-15T15:56:49+0000","dateStarted":"2019-06-15T18:29:59+0000","dateFinished":"2019-06-15T18:29:59+0000","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:1542"},{"text":"%spark\n\n// prove that you can get a Spark SQLContext (I think this is deprecated)\n\nsqlContext\n","user":"anonymous","dateUpdated":"2019-06-15T18:30:09+0000","config":{"colWidth":12,"editorMode":"ace/mode/scala","results":{},"enabled":true,"editorSetting":{"language":"scala","editOnDblClick":false}},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1560614209705_-500101628","id":"20190530-144334_508411187","dateCreated":"2019-06-15T15:56:49+0000","dateStarted":"2019-06-15T18:30:09+0000","dateFinished":"2019-06-15T18:30:10+0000","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:1543"},{"text":"%spark\n\n// prove that you can get a Spark Session (I think I'm supposed to use this instead of SQLContext)\n\nspark","user":"anonymous","dateUpdated":"2019-06-15T18:30:37+0000","config":{"colWidth":12,"editorMode":"ace/mode/scala","results":{},"enabled":true,"editorSetting":{"language":"scala","editOnDblClick":false}},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1560614209706_-498947381","id":"20190530-145225_2110572036","dateCreated":"2019-06-15T15:56:49+0000","dateStarted":"2019-06-15T18:30:37+0000","dateFinished":"2019-06-15T18:30:38+0000","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:1544"},{"text":"%spark\n\n// prove that you can do a low-level read from C*\n\nval tableRDD = sc.cassandraTable(\"analytics_workshop\", \"countries\")\ntableRDD.take(10)","user":"anonymous","dateUpdated":"2019-06-15T18:30:56+0000","config":{"colWidth":12,"editorMode":"ace/mode/scala","results":{"0":{"graph":{"mode":"table","height":87,"optionOpen":false}}},"enabled":true,"editorSetting":{"language":"scala","editOnDblClick":false}},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1560614209708_-501255874","id":"20190530-145409_300100572","dateCreated":"2019-06-15T15:56:49+0000","dateStarted":"2019-06-15T18:30:43+0000","dateFinished":"2019-06-15T18:30:45+0000","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:1545"},{"text":"%spark\n\n// prove that you can use the Cassandra Connector\n\nval qry = sc.cassandraTable(\"analytics_workshop\", \"countries\").select(\"country\").where(\"country = 'Madagascar'\")\nval resultRDD = qry.collect\nresultRDD.foreach(row => println(row.getString(\"country\")))","user":"anonymous","dateUpdated":"2019-06-15T18:31:02+0000","config":{"colWidth":12,"editorMode":"ace/mode/scala","results":{},"enabled":true,"editorSetting":{"language":"scala","editOnDblClick":false}},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1560614209709_-501640623","id":"20190530-152318_1800161658","dateCreated":"2019-06-15T15:56:49+0000","dateStarted":"2019-06-15T18:31:02+0000","dateFinished":"2019-06-15T18:31:03+0000","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:1546"},{"text":"%spark\n\n// DO THIS ONLY ONCE PER SESSION!!!\n// Before you use Spark SQL queries, you must do a 1-time registration of each table you want to use\n// I *think* you do not need this if you do a dse spark-submit\n\nvar createDDL = \"CREATE TEMPORARY VIEW countries USING org.apache.spark.sql.cassandra OPTIONS ( table 'countries', keyspace 'analytics_workshop', cluster 'Cluster 1', pushdown 'true')\";\n\nspark.sql(createDDL);\n\t\t","user":"anonymous","dateUpdated":"2019-06-15T18:31:41+0000","config":{"colWidth":12,"editorMode":"ace/mode/scala","results":{},"enabled":true,"editorSetting":{"language":"scala","editOnDblClick":false}},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1560614209710_-500486377","id":"20190530-160147_749487410","dateCreated":"2019-06-15T15:56:49+0000","dateStarted":"2019-06-15T18:31:41+0000","dateFinished":"2019-06-15T18:31:49+0000","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:1547"},{"text":"%spark\n\n// prove that you can query with Spark SQL\n\nvar ds = spark.sql(\"SELECT * FROM countries WHERE country = 'Madagascar'\");\nds.show\n","user":"anonymous","dateUpdated":"2019-06-15T18:32:03+0000","config":{"colWidth":12,"editorMode":"ace/mode/scala","results":{},"enabled":true,"editorSetting":{"language":"scala","editOnDblClick":false}},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1560614209711_-500871126","id":"20190530-192655_1285746303","dateCreated":"2019-06-15T15:56:49+0000","dateStarted":"2019-06-15T18:32:03+0000","dateFinished":"2019-06-15T18:32:04+0000","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:1548"},{"text":"%spark\n","dateUpdated":"2019-06-15T15:56:49+0000","config":{"colWidth":12,"editorMode":"ace/mode/scala","results":{},"enabled":true,"editorSetting":{"language":"scala","editOnDblClick":false}},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1560614209712_-490482905","id":"20190530-194003_392853198","dateCreated":"2019-06-15T15:56:49+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:1549"}],"name":"bkplay","id":"2EG6NWVVY","angularObjects":{"2EG82R1CT:shared_process":[],"2EGDJGTTF:shared_process":[],"2EDDSRFGQ:shared_process":[],"2EDQSPH14:shared_process":[],"2EGANEBGU:shared_process":[],"2EFGW11TW:shared_process":[],"2ECK9UCRJ:shared_process":[],"2ED1GX1AD:shared_process":[],"2EEYRTZAY:shared_process":[],"2EEE1MG63:shared_process":[],"2EFY218XD:shared_process":[],"2EE2ZX7EQ:shared_process":[],"2EDKUCTN1:shared_process":[],"2EEG6D3PT:shared_process":[],"2EEV6VR86:shared_process":[],"2EF1XKYD2:shared_process":[],"2EEDVMK8C:shared_process":[],"2EDVP4F4X:shared_process":[],"2EFSSKAXV:shared_process":[]},"config":{"looknfeel":"default","personalizedMode":"false"},"info":{}}