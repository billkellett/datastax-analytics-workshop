{"paragraphs":[{"text":"%md\n\ncell 1\n\n# **Lab 2 - Calculate Average Ratings**\n\nRightVest customers write reviews of their investment choices.  The reviews include a rating from 1 to 5 stars.  For each investment instrument, customers want to see the **average** rating across all reviews.  \n\nIt is not feasible to calculate the average rating on-demand whenever a customer views an investment instrument.  For any given instrument, there might be tens of thousands of reviews.  We cannot calculate the average on the fly and still provide sub-second response time.  Therefore, RightVest runs a Spark SQL job once every hour in order to calculate the latest average user rating for every investment instrument.\n\n### **Persona:** Grace Hopper, Engineering Manager at RightVest\n\nGrace and her team must plan and execute a development sprint that will create this hourly batch job. \n\n### **User Story:** Calculate average user rating for every investment instrument. \n\nWe must do the following\n\n- Read every investment instrument\n- For each instrument, read all user review records, and aggregate the star-rating into an average user review rating for that instrument\n- Persist the newly-calculated average into a table specially built for this purpose.  When web pages are served, they can use data from this table to show the average rating very quickly.","user":"anonymous","dateUpdated":"2019-06-19T19:52:17+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p>cell 1</p>\n<h1><strong>Lab 2 - Calculate Average Ratings</strong></h1>\n<p>RightVest customers write reviews of their investment choices. The reviews include a rating from 1 to 5 stars. For each investment instrument, customers want to see the <strong>average</strong> rating across all reviews. </p>\n<p>It is not feasible to calculate the average rating on-demand whenever a customer views an investment instrument. For any given instrument, there might be tens of thousands of reviews. We cannot calculate the average on the fly and still provide sub-second response time. Therefore, RightVest runs a Spark SQL job once every hour in order to calculate the latest average user rating for every investment instrument.</p>\n<h3><strong>Persona:</strong> Grace Hopper, Engineering Manager at RightVest</h3>\n<p>Grace and her team must plan and execute a development sprint that will create this hourly batch job. </p>\n<h3><strong>User Story:</strong> Calculate average user rating for every investment instrument.</h3>\n<p>We must do the following</p>\n<ul>\n  <li>Read every investment instrument</li>\n  <li>For each instrument, read all user review records, and aggregate the star-rating into an average user review rating for that instrument</li>\n  <li>Persist the newly-calculated average into a table specially built for this purpose. When web pages are served, they can use data from this table to show the average rating very quickly.</li>\n</ul>\n</div>"}]},"apps":[],"jobName":"paragraph_1560967881474_-1461957606","id":"20190615-193334_2123319074","dateCreated":"2019-06-19T18:11:21+0000","dateStarted":"2019-06-19T19:52:17+0000","dateFinished":"2019-06-19T19:52:17+0000","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:14782"},{"text":"%md\ncell 2\n\n## Examining our data...\n\nExecute the cell below to examine the Cassandra Keyspace we will be using in this workshop..\n\nTake a few minutes to examine the following tables:\n\n- review\n- avg_review","user":"anonymous","dateUpdated":"2019-06-19T18:27:50+0000","config":{"editorSetting":{"language":"markdown","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":true,"results":{},"enabled":true,"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p>cell 2</p>\n<h2>Examining our data&hellip;</h2>\n<p>Execute the cell below to examine the Cassandra Keyspace we will be using in this workshop..</p>\n<p>Take a few minutes to examine the following tables:</p>\n<ul>\n  <li>review</li>\n  <li>avg_review</li>\n</ul>\n</div>"}]},"apps":[],"jobName":"paragraph_1560967881479_-1463881351","id":"20190615-194453_782238367","dateCreated":"2019-06-19T18:11:21+0000","dateStarted":"2019-06-19T18:27:50+0000","dateFinished":"2019-06-19T18:27:50+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:14783"},{"text":"%cassandra\n\n// cell 3\n\n// Examine our DSE Keyspace \n// Note that in this cell, we are using Cassandra CQL, not Spark SQL.\n// For this lab, we are interested in the \"review\" and \"avg_review\" tables\n\ndescribe keyspace analytics_workshop;","user":"anonymous","dateUpdated":"2019-06-19T18:28:28+0000","config":{"colWidth":12,"editorMode":"ace/mode/undefined","results":{},"enabled":true,"editorSetting":{"language":"scala","editOnDblClick":false}},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1560967881480_-1465805095","id":"20190529-161317_30181527","dateCreated":"2019-06-19T18:11:21+0000","dateStarted":"2019-06-19T18:28:28+0000","dateFinished":"2019-06-19T18:28:29+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:14784","errorMessage":""},{"text":"%spark\n\n// cell 4\n\n// RUN THIS ONLY ONCE PER SESSION\n// Before you use Spark SQL queries, you must do a 1-time registration of each table you want to use (there is no IF NOT EXISTS option)\n// You do not need this if you do a dse spark-submit, which pre-registers all tables\n\nvar createDDL = \"CREATE TEMPORARY VIEW avg_review USING org.apache.spark.sql.cassandra OPTIONS ( table 'avg_review', keyspace 'analytics_workshop', cluster 'Cluster 1', pushdown 'true')\"\nspark.sql(createDDL)\n\nvar createDDL = \"CREATE TEMPORARY VIEW review USING org.apache.spark.sql.cassandra OPTIONS ( table 'review', keyspace 'analytics_workshop', cluster 'Cluster 1', pushdown 'true')\"\nspark.sql(createDDL)","user":"anonymous","dateUpdated":"2019-06-19T18:30:56+0000","config":{"colWidth":12,"editorMode":"ace/mode/scala","results":{},"enabled":true,"editorSetting":{"language":"scala","editOnDblClick":false}},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1560967881482_-1465035597","id":"20190615-195433_1606768454","dateCreated":"2019-06-19T18:11:21+0000","dateStarted":"2019-06-19T18:30:56+0000","dateFinished":"2019-06-19T18:31:20+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:14785","errorMessage":""},{"text":"%spark\n\n// cell 5\n\n// Now let's take a look at the initial state of the \"review\" table\n\nvar ds = spark.sql(\"SELECT * FROM review\");\nds.show","user":"anonymous","dateUpdated":"2019-06-19T21:02:10+0000","config":{"colWidth":12,"editorMode":"ace/mode/scala","results":{},"enabled":true,"editorSetting":{"language":"scala","editOnDblClick":false}},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1560967881483_-1465420346","id":"20190615-184855_149703656","dateCreated":"2019-06-19T18:11:21+0000","dateStarted":"2019-06-19T21:02:10+0000","dateFinished":"2019-06-19T21:02:10+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:14786","errorMessage":""},{"text":"%spark\n\n// cell 6\n\n// How many reviews do we have?\n\nvar ds = spark.sql(\"SELECT COUNT(*) FROM review\")\nds.show","user":"anonymous","dateUpdated":"2019-06-19T21:02:15+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1560969787203_1295721945","id":"20190619-184307_1258099386","dateCreated":"2019-06-19T18:43:07+0000","dateStarted":"2019-06-19T21:02:15+0000","dateFinished":"2019-06-19T21:02:15+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:14787","errorMessage":""},{"text":"%spark\n\n// cell 7\n\n// Next, let's look at the initial state of the \"avg_review\" table.\n\nvar ds = spark.sql(\"SELECT * FROM avg_review\");\nds.show\n","user":"anonymous","dateUpdated":"2019-06-19T21:02:20+0000","config":{"colWidth":12,"editorMode":"ace/mode/scala","results":{},"enabled":true,"editorSetting":{"language":"scala","editOnDblClick":false}},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1560967881484_-1467344091","id":"20190615-201132_1184275073","dateCreated":"2019-06-19T18:11:21+0000","dateStarted":"2019-06-19T21:02:20+0000","dateFinished":"2019-06-19T21:02:20+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:14788","errorMessage":""},{"text":"%spark\n\n// cell 8\n\n// How many avg_review rows do we have?\n\nvar ds = spark.sql(\"SELECT COUNT(*) FROM avg_review\");\nds.show","user":"anonymous","dateUpdated":"2019-06-19T21:02:25+0000","config":{"colWidth":12,"editorMode":"ace/mode/scala","results":{},"enabled":true,"editorSetting":{"language":"scala","editOnDblClick":false}},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1560967881485_-1467728840","id":"20190616-130108_1826314840","dateCreated":"2019-06-19T18:11:21+0000","dateStarted":"2019-06-19T21:02:25+0000","dateFinished":"2019-06-19T21:02:25+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:14789","errorMessage":""},{"text":"%spark\n\n// cell 9\n\n// Let's use a SELECT with an aggregation just to see how we would like the average review data to be shaped.\n\nvar ds = spark.sql(\"SELECT \"\n                        + \"instrument_symbol, \"\n                        + \"avg(review_stars) AS avg_review_stars, \"\n                        + \"max(CURRENT_DATE()) AS last_updated \"\n                    + \"FROM review \"\n                    + \"GROUP BY instrument_symbol\")\nds.show","user":"anonymous","dateUpdated":"2019-06-19T21:02:30+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1560970218580_1454112086","id":"20190619-185018_796881020","dateCreated":"2019-06-19T18:50:18+0000","dateStarted":"2019-06-19T21:02:30+0000","dateFinished":"2019-06-19T21:02:31+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:14790","errorMessage":""},{"text":"%spark\n\n// cell 10\n\n// Now we'll use the same query as above, but use it to provide the values for an INSERT statement.\n// Remember that Spark SQL does not support UPDATE.  It does support INSERT (since Spark SQL can treat inserts as appends).  \n// However, remember the UPSERT behavior of Cassandra!  This will allow us to use the INSERT command, but achieve the effect of an update.\n// When you use this technique, remember that you MUST populate every column.  Any column you ignore will be NULLed in the Cassandra table.\n\nvar ds = spark.sql(\"INSERT INTO avg_review \"\n                         + \"SELECT \"\n                             + \"instrument_symbol, \"\n                             + \"avg(review_stars) AS avg_review_stars, \"\n                             + \"max(CURRENT_DATE()) AS last_updated \"\n                         + \"FROM review \"\n                         + \"GROUP BY instrument_symbol \")","user":"anonymous","dateUpdated":"2019-06-19T21:02:38+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1560970473268_-1850543834","id":"20190619-185433_2101188641","dateCreated":"2019-06-19T18:54:33+0000","dateStarted":"2019-06-19T21:02:38+0000","dateFinished":"2019-06-19T21:02:40+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:14791","errorMessage":""},{"text":"%spark\n\n// cell 11\n\n// Now let's verify that the avg_review table was actually updated.\n// Yes, it was... but note that there are a few rows that still have a '1' in the last_updated column.\n// That's because there were no user reviews for those rows, so they were left unchanged.  \n\nvar ds = spark.sql(\"SELECT * FROM avg_review\")\nds.show(100)","user":"anonymous","dateUpdated":"2019-06-19T21:02:48+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1560971791599_-1803147508","id":"20190619-191631_1945050141","dateCreated":"2019-06-19T19:16:31+0000","dateStarted":"2019-06-19T21:02:48+0000","dateFinished":"2019-06-19T21:02:48+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:14792","errorMessage":""},{"text":"%cassandra\n\n// cell 12\n\n// Let's just double-check that Cassandra was actually updated by repeating the above query with CQL\n\nSELECT * from analytics_workshop.avg_review;\n","user":"anonymous","dateUpdated":"2019-06-19T21:02:58+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"text","editOnDblClick":false},"editorMode":"ace/mode/undefined"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1560976868750_352242069","id":"20190619-204108_1718962875","dateCreated":"2019-06-19T20:41:08+0000","dateStarted":"2019-06-19T21:02:58+0000","dateFinished":"2019-06-19T21:02:58+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:14793","errorMessage":""},{"text":"%md\n\ncell 13\n\n## Mission accomplished!\n\nAt this point we have reached our goal for this lab.  We have created a Spark-SQL job that we could run periodically to calculate and persist average review scores for each investment instrument.\n\nThe cells below are useful if you want to reset the data and run the above steps again...\n","user":"anonymous","dateUpdated":"2019-06-19T20:42:53+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p>cell 13</p>\n<h2>Mission accomplished!</h2>\n<p>At this point we have reached our goal for this lab. We have created a Spark-SQL job that we could run periodically to calculate and persist average review scores for each investment instrument.</p>\n<p>The cells below are useful if you want to reset the data and run the above steps again&hellip;</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1560976544543_272757222","id":"20190619-203544_1056633227","dateCreated":"2019-06-19T20:35:44+0000","dateStarted":"2019-06-19T20:42:53+0000","dateFinished":"2019-06-19T20:42:53+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:14794"},{"text":"%cassandra\n\n// cell 14\n\n// Use CQL to truncate the avg_review table.\n\nTRUNCATE TABLE analytics_workshop.avg_review;","user":"anonymous","dateUpdated":"2019-06-19T20:50:39+0000","config":{"colWidth":12,"editorMode":"ace/mode/undefined","results":{},"enabled":true,"editorSetting":{"language":"text","editOnDblClick":false}},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1560967881513_-1478501809","id":"20190530-194003_392853198","dateCreated":"2019-06-19T18:11:21+0000","dateStarted":"2019-06-19T20:50:39+0000","dateFinished":"2019-06-19T20:50:39+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:14795","errorMessage":""},{"text":"%spark\n\n// cell 15\n\n// Now get row count in Spark just to prove that everything is in sync.\n\nvar ds = spark.sql(\"SELECT COUNT(*) FROM avg_review\")\nds.show","user":"anonymous","dateUpdated":"2019-06-19T20:50:59+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1560977099655_-1012925294","id":"20190619-204459_1429834182","dateCreated":"2019-06-19T20:44:59+0000","dateStarted":"2019-06-19T20:50:59+0000","dateFinished":"2019-06-19T20:51:00+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:14796","errorMessage":""},{"text":"%md\n\ncell 16\n\nNow open a terminal and enter the following to reload the original data.\n\n`\ncqlsh node0\n`\n\n`\ncopy analytics_workshop.avg_review (\n  instrument_symbol,\n  last_updated,\n  avg_review_stars\n)\n  from '/tmp/datastax-spark-sql-workshop/data/analytics_workshop.avg_review.csv'\n  with HEADER = TRUE;\n`\n","user":"anonymous","dateUpdated":"2019-06-19T21:00:03+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p>cell 16</p>\n<p>Now open a terminal and enter the following to reload the original data.</p>\n<p><code>\ncqlsh node0\n</code></p>\n<p><code>\ncopy analytics_workshop.avg_review (\n  instrument_symbol,\n  last_updated,\n  avg_review_stars\n)\n  from &#39;/tmp/datastax-spark-sql-workshop/data/analytics_workshop.avg_review.csv&#39;\n  with HEADER = TRUE;\n</code></p>\n</div>"}]},"apps":[],"jobName":"paragraph_1560977238709_-1085041904","id":"20190619-204718_1311902155","dateCreated":"2019-06-19T20:47:18+0000","dateStarted":"2019-06-19T21:00:03+0000","dateFinished":"2019-06-19T21:00:03+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:14797"},{"text":"%spark\n\n// cell 17\n\n// Read the table just to make sure the data was loaded.\n\nvar ds = spark.sql(\"SELECT * FROM avg_review\")\nds.show","user":"anonymous","dateUpdated":"2019-06-19T21:01:04+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"text","editOnDblClick":false},"editorMode":"ace/mode/text"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1560977655148_-1088921163","id":"20190619-205415_9130503","dateCreated":"2019-06-19T20:54:15+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:14798","dateFinished":"2019-06-19T21:01:04+0000","dateStarted":"2019-06-19T21:01:04+0000","errorMessage":""},{"text":"%md\n\ncell 18\n\nNow you can re-run the aggregate/persist steps if you wish.\n","user":"anonymous","dateUpdated":"2019-06-19T21:01:48+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1560978064198_1410438341","id":"20190619-210104_1548989952","dateCreated":"2019-06-19T21:01:04+0000","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:16128","dateFinished":"2019-06-19T21:01:48+0000","dateStarted":"2019-06-19T21:01:48+0000","results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p>cell 18</p>\n<p>Now you can re-run the aggregate/persist steps if you wish.</p>\n</div>"}]}},{"text":"%md\n","user":"anonymous","dateUpdated":"2019-06-19T21:01:48+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1560978108022_-1174643547","id":"20190619-210148_86481232","dateCreated":"2019-06-19T21:01:48+0000","status":"READY","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:16213"}],"name":"Lab_2_-_Spark-SQL_for_OLTP_Aggregations","id":"2EFQUWUCD","angularObjects":{"2EDRCK444:shared_process":[],"2EG6EH995:shared_process":[],"2ECW3MYU6:shared_process":[],"2ED317J9D:shared_process":[],"2EEK98XHP:shared_process":[],"2EG5BQZDD:shared_process":[],"2EDDD7T4V:shared_process":[],"2EDX73YGS:shared_process":[],"2EF87MX4D:shared_process":[],"2EEKG5TYA:shared_process":[],"2EFGXQDF5:shared_process":[],"2EF9SEK66:shared_process":[],"2EER36UHT:shared_process":[],"2EEP233DK:shared_process":[],"2EG7WYKTC:shared_process":[],"2EGB65A5F:shared_process":[],"2EDN312P6:shared_process":[],"2ED5TBT16:shared_process":[],"2EE78ATB9:shared_process":[]},"config":{"looknfeel":"default","personalizedMode":"false"},"info":{}}